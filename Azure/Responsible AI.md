Responsible AI focuses in ethical, transparent and accountable use of AI technologies.
Microsoft puts into practice Responsible AI via its six  **Microsoft AI principles**
* Fairness : AI systems should treat all people fairly.
		Bias can be introduced during the development of a pipeline.
		Azure Ml can tell how each feature can influence a model's prediction for bias.
		Open-source tool :  Fear-learn (Python)
* Reliability and safety : AI systems should perform reliably and safely.
		AI systems must be rigorously tested to ensure the work as expected before release to the end user.
		If there are scenarios where AI is making mistakes its important to release a **report quantified risks and harms** to end-users so they are informed of the short-comings of an AI solution (eg Autonomous vehicles, Health diagnosis)
* Privacy and security : AI systems should be secure and respect privacy .
		AI require vast amount of data to train Deep learning models. Some of the ML models might require PII data (Personally Identifiable information).
		It's important to ensure protection of user data that it is not leaked or disclosed.
* Inclusiveness : AI systems should empower everyone and engage people
		
* Transparency  : AI systems should be understandable
		Interpretability / Intelligibility (Being clear) is when end-users can understand the behavior of the UI.
* Accountability : People should be accountable for AI systems